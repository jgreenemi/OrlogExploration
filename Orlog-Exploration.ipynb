{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explores the game of Orlog from Assassin's Creed: Valhalla, in search of an optimal policy for winning games.\n",
    "\n",
    "In the very short description, we can probably approach this as a state table with a Q-learning approach. We treat the game as an MDP since prior turns in the game do not change what information we gain about the game's progress when we know the current turn. Each game (multiple turns) is a single episode. Games are short (there are few state changes) so we can update the policy at the end of each episode - needn't look into temporal difference approaches.\n",
    "\n",
    "To make the development on the game and algorithm fast, we can simplify the game down to the core pieces:\n",
    "\n",
    "1. Player flips a coin to determine who goes first.\n",
    "1. Player rolls a single dice up to three times and chooses which roll result they want to keep.\n",
    "1. Opponent does the same.\n",
    "1. Resolution occurs.\n",
    "1. If there is health on both sides of the game, repeat previous three steps. Else, player with health remaining is the winner.\n",
    "1. Policy is updated based on which moves resulted in a win and which resulted in a loss.\n",
    "1. Repeat until a policy is developed that consistently wins games better than random strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "\n",
    "* Create game representation.\n",
    "* Create random strategy.\n",
    "* Pull metrics on win/loss rate for random strategy. This serves as the baseline.\n",
    "* Review algorithms available to us and pass the game representation into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (this env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
